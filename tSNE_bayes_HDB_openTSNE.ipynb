{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO+ZjX81olAgOEYQwuZ5M7B",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mdlakic/t-SNE_binning/blob/main/tSNE_bayes_HDB_openTSNE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ### Program settings\n",
        "bins = \"bins\" #@param {type:\"string\"}\n",
        "#@markdown - Type the directory name where binned contigs will be saved \n",
        "image_alpha = 0.3 #@param [0.1,0.3,0.5,0.8,1.0 ] {type:\"raw\"}\n",
        "#@markdown - Specify the shade of ellipses - high numbers make darker ellipses, while small are more transparet\n",
        "tsne_plot = \"contigs_opentSNE_HDB_clusters.png\" #@param {type:\"string\"}\n",
        "#@markdown - Type name of the plot file with tSNE clusters \n",
        "num_recycles = \"auto\" #@param [\"auto\", \"0\", \"1\", \"3\", \"6\", \"12\", \"24\", \"48\"]\n",
        "recycle_early_stop_tolerance = \"auto\" #@param [\"auto\", \"0.0\", \"0.5\", \"1.0\"]\n",
        "#@markdown - if `auto` selected, will use 20 recycles if `model_type=alphafold2_multimer_v3` (with tol=0.5), all else 3 recycles (with tol=0.0).\n",
        "\n",
        "#@markdown #### Sample settings\n",
        "#@markdown -  enable dropouts and increase number of seeds to sample predictions from uncertainty of the model.\n",
        "#@markdown -  decrease `max_msa` to increase uncertainity\n",
        "max_msa = \"auto\" #@param [\"auto\", \"512:1024\", \"256:512\", \"64:128\", \"32:64\", \"16:32\"]\n",
        "num_seeds = 1 #@param [1,2,4,8,16] {type:\"raw\"}\n",
        "use_dropout = False #@param {type:\"boolean\"}\n",
        "\n",
        "num_recycles = None if num_recycles == \"auto\" else int(num_recycles)\n",
        "recycle_early_stop_tolerance = None if recycle_early_stop_tolerance == \"auto\" else float(recycle_early_stop_tolerance)\n",
        "if max_msa == \"auto\": max_msa = None\n",
        "\n",
        "parser = argparse.ArgumentParser(\n",
        "                                 description='\\n Calculate and plot tSNE clusters from a set of metagenomic contig sequences.\\n',\n",
        "                                 epilog='\\n \\n',\n",
        "                                 formatter_class=argparse.RawDescriptionHelpFormatter)\n",
        "parser.add_argument(\n",
        "                    'input_file', help='path to the input contig file [HAS TO BE TYPED LAST]')\n",
        "parser.add_argument('-bins',\n",
        "                    dest='bins',\n",
        "                    help='subdirectory to save binned sequences [default: bins]',\n",
        "                    type=np.str,\n",
        "                    default='bins',\n",
        "                    required=False)\n",
        "parser.add_argument('-alpha',\n",
        "                    dest='image_alpha',\n",
        "                    help='shade of ellipses - higher is darker [default: 0.3]',\n",
        "                    type=np.float,\n",
        "                    default=0.3,\n",
        "                    required=False)\n",
        "parser.add_argument('-dim',\n",
        "                    dest='dims',\n",
        "                    choices=[2, 3],\n",
        "                    help='dimensionality of tSNE [default: 2]',\n",
        "                    type=np.int,\n",
        "                    default=2,\n",
        "                    required=False)\n",
        "parser.add_argument('-plot',\n",
        "                    dest='tsne_plot',\n",
        "                    help='plot file with tSNE clusters [default: \"contigs_opentSNE_HDB_clusters.png\"]',\n",
        "                    type=np.str,\n",
        "                    default='contigs_opentSNE_HDB_clusters.png',\n",
        "                    required=False)\n",
        "parser.add_argument('-ptitle',\n",
        "                    dest='plot_title',\n",
        "                    help='final plot title [default: \"tSNE embedding\"]',\n",
        "                    type=np.str,\n",
        "                    default='tSNE embedding',\n",
        "                    required=False)\n",
        "parser.add_argument('-bb',\n",
        "                    dest='black_bkg',\n",
        "                    help='use black background instead of white for tSNE plot',\n",
        "                    action='store_true',\n",
        "                    default=False,\n",
        "                    required=False)\n",
        "parser.add_argument('-kmer',\n",
        "                    dest='kmer_size',\n",
        "                    choices=[4, 5],\n",
        "                    help='kmer size for frequency calculation [default: 4]',\n",
        "                    type=np.int,\n",
        "                    default=4,\n",
        "                    required=False)\n",
        "parser.add_argument('-lc',\n",
        "                    dest='low_cutoff',\n",
        "                    choices=['1k', '2k', '3k', '4k', '5k', '7k'],\n",
        "                    help='cutoff size to retain contigs [default: 2k]',\n",
        "                    type=np.str,\n",
        "                    default='2k',\n",
        "                    required=False)\n",
        "parser.add_argument('-hc',\n",
        "                    dest='high_cutoff',\n",
        "                    choices=['10k', '20k'],\n",
        "                    help='cutoff size for contigs for chopping [default: 10k]',\n",
        "                    type=np.str,\n",
        "                    default='10k',\n",
        "                    required=False)\n",
        "parser.add_argument('-clu',\n",
        "                    dest='tsne_clusters',\n",
        "                    help='CSV file with tSNE clusters [default: \"[2D/3D]_contigs_opentSNE_HDB_clusters.csv\"]',\n",
        "                    type=np.str,\n",
        "                    default='contigs_opentSNE_HDB_clusters.csv',\n",
        "                    required=False)\n",
        "parser.add_argument('-nt',\n",
        "                    dest='noise_threshold',\n",
        "                    help='acceptable fraction of throwaway data points [default: 0.2]',\n",
        "#                    help='acceptable fraction of throwaway data points [default: 1.0; accept all solutions]',\n",
        "                    type=np.float,\n",
        "                    default=0.2,\n",
        "#                    default=1.0,\n",
        "                    required=False)\n",
        "parser.add_argument('-tm',\n",
        "                    dest='tsne_metric',\n",
        "                    choices=['euclidean', 'cosine', 'manhattan', 'cityblock'],\n",
        "                    help='t-SNE metric [default: cosine]',\n",
        "                    type=np.str,\n",
        "                    default='cosine',\n",
        "                    required=False)\n",
        "parser.add_argument('-nobayes',\n",
        "                    dest='hyperopt',\n",
        "                    help='do not use bayesian parameter optimization during clustering instead of grid search [default: use it]',\n",
        "                    action='store_false',\n",
        "                    default=True,\n",
        "                    required=False)\n",
        "parser.add_argument('-ica',\n",
        "                    dest='ica',\n",
        "                    help='use FastICA before tSNE [default: do not use it]',\n",
        "                    action='store_true',\n",
        "                    default=False,\n",
        "                    required=False)\n",
        "parser.add_argument('-perp',\n",
        "                    dest='perplexity',\n",
        "                    help='perplexity [default: 40]',\n",
        "                    type=np.int,\n",
        "                    default=40,\n",
        "                    required=False)\n",
        "parser.add_argument('-psize',\n",
        "                    dest='point_size',\n",
        "                    choices=[2, 5, 10],\n",
        "                    help='size of data points in tSNE plot [default: 5]',\n",
        "                    type=np.int,\n",
        "                    default=5,\n",
        "                    required=False)\n",
        "parser.add_argument('-cpus',\n",
        "                    dest='threads',\n",
        "                    help='number of threads to use [default: (total-2)]',\n",
        "                    type=np.int,\n",
        "                    default=-3,\n",
        "                    required=False)\n",
        "parser.add_argument('-theta',\n",
        "                    dest='theta_val',\n",
        "                    help='theta angle, 0.5 for bh_tsne ; closer to zero is slow but accurate [default: based on data size]',\n",
        "                    type=np.float,\n",
        "                    default=-1.0,\n",
        "                    required=False)\n",
        "parser.add_argument('-ie',\n",
        "                    dest='initial_embedding',\n",
        "                    choices=['pca', 'spectral'],\n",
        "                    help='embedding initialization [default: spectral]',\n",
        "                    type=np.str,\n",
        "                    default='spectral',\n",
        "                    required=False)\n",
        "parser.add_argument('-quiet',\n",
        "                    dest='verbose',\n",
        "                    help='do not show progress info',\n",
        "                    action='store_false',\n",
        "                    default=True,\n",
        "                    required=False)\n",
        "parser.add_argument('-seed',\n",
        "                    dest='rand_seed',\n",
        "                    help='random seed tSNE embedding [default: None]',\n",
        "                    type=np.int,\n",
        "                    default=-1,\n",
        "                    required=False)\n",
        "\n",
        "args = parser.parse_args()\n",
        "fmt = FormatScalarFormatter('%d')\n",
        "jobs = args.threads\n",
        "hdb_model = 'HDB_' + os.path.splitext(args.tsne_plot)[0] + '_model.joblib'\n",
        "if (args.rand_seed == -1):\n",
        "    rand_num = np.random.randint(1000000)\n",
        "else:\n",
        "    rand_num = args.rand_seed\n",
        "\n",
        "if args.low_cutoff == '1k':\n",
        "    lc_size = 1000\n",
        "    lc_abbrev = '1K'\n",
        "if args.low_cutoff == '2k':\n",
        "    lc_size = 2000\n",
        "    lc_abbrev = '2K'\n",
        "if args.low_cutoff == '3k':\n",
        "    lc_size = 3000\n",
        "    lc_abbrev = '3K'\n",
        "if args.low_cutoff == '4k':\n",
        "    lc_size = 4000\n",
        "    lc_abbrev = '4K'\n",
        "if args.low_cutoff == '5k':\n",
        "    lc_size = 5000\n",
        "    lc_abbrev = '5K'\n",
        "if args.low_cutoff == '7k':\n",
        "    lc_size = 7000\n",
        "    lc_abbrev = '7K'\n",
        "if args.high_cutoff == '10k':\n",
        "    hc_size = 10000\n",
        "    hc_abbrev = '10K'\n",
        "if args.high_cutoff == '20k':\n",
        "    hc_size = 20000\n",
        "    hc_abbrev = '20K'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "uG3HDd64GZw1",
        "outputId": "7c59364d-5976-42ff-dfbe-4929aa2c8869"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "usage: ipykernel_launcher.py [-h] [-bins BINS] [-alpha IMAGE_ALPHA]\n",
            "                             [-dim {2,3}] [-plot TSNE_PLOT]\n",
            "                             [-ptitle PLOT_TITLE] [-bb] [-kmer {4,5}]\n",
            "                             [-lc {1k,2k,3k,4k,5k,7k}] [-hc {10k,20k}]\n",
            "                             [-clu TSNE_CLUSTERS] [-nt NOISE_THRESHOLD]\n",
            "                             [-tm {euclidean,cosine,manhattan,cityblock}]\n",
            "                             [-nobayes] [-ica] [-perp PERPLEXITY]\n",
            "                             [-psize {2,5,10}] [-cpus THREADS]\n",
            "                             [-theta THETA_VAL] [-ie {pca,spectral}] [-quiet]\n",
            "                             [-seed RAND_SEED]\n",
            "                             input_file\n",
            "ipykernel_launcher.py: error: unrecognized arguments: -f\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "SystemExit",
          "evalue": "ignored",
          "traceback": [
            "An exception has occurred, use %tb to see the full traceback.\n",
            "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5JGhtjOlFRS6",
        "outputId": "19421155-e2dc-4373-a7f4-56ffff3b382d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: checkm-genome in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Requirement already satisfied: dendropy>=4.5.2 in /usr/local/lib/python3.10/dist-packages (from checkm-genome) (4.6.0)\n",
            "Requirement already satisfied: scipy>=1.7.3 in /usr/local/lib/python3.10/dist-packages (from checkm-genome) (1.10.1)\n",
            "Requirement already satisfied: matplotlib>=3.5.1 in /usr/local/lib/python3.10/dist-packages (from checkm-genome) (3.7.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from checkm-genome) (67.7.2)\n",
            "Requirement already satisfied: pysam>=0.19.0 in /usr/local/lib/python3.10/dist-packages (from checkm-genome) (0.21.0)\n",
            "Requirement already satisfied: numpy>=1.21.3 in /usr/local/lib/python3.10/dist-packages (from checkm-genome) (1.22.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.1->checkm-genome) (1.0.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.1->checkm-genome) (1.4.4)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.1->checkm-genome) (8.4.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.1->checkm-genome) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.1->checkm-genome) (4.39.3)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.1->checkm-genome) (3.0.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.1->checkm-genome) (23.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.1->checkm-genome) (2.8.2)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.10/dist-packages (from pysam>=0.19.0->checkm-genome) (0.29.34)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.5.1->checkm-genome) (1.16.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: opentsne==0.7.1 in /usr/local/lib/python3.10/dist-packages (0.7.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from opentsne==0.7.1) (1.10.1)\n",
            "Requirement already satisfied: scikit-learn>=0.20 in /usr/local/lib/python3.10/dist-packages (from opentsne==0.7.1) (1.2.2)\n",
            "Requirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.10/dist-packages (from opentsne==0.7.1) (1.22.4)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20->opentsne==0.7.1) (3.1.0)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20->opentsne==0.7.1) (1.2.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: hdbscan==0.8.29 in /usr/local/lib/python3.10/dist-packages (0.8.29)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from hdbscan==0.8.29) (1.22.4)\n",
            "Requirement already satisfied: scikit-learn>=0.20 in /usr/local/lib/python3.10/dist-packages (from hdbscan==0.8.29) (1.2.2)\n",
            "Requirement already satisfied: scipy>=1.0 in /usr/local/lib/python3.10/dist-packages (from hdbscan==0.8.29) (1.10.1)\n",
            "Requirement already satisfied: cython>=0.27 in /usr/local/lib/python3.10/dist-packages (from hdbscan==0.8.29) (0.29.34)\n",
            "Requirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.10/dist-packages (from hdbscan==0.8.29) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20->hdbscan==0.8.29) (3.1.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: wget in /usr/local/lib/python3.10/dist-packages (3.2)\n",
            "usage: cut_up_fasta.py\n",
            "       [-h]\n",
            "       [-c CHUNK_SIZE]\n",
            "       [-o OVERLAP_SIZE]\n",
            "       [-m]\n",
            "       [-b BEDFILE]\n",
            "       contigs\n",
            "       [contigs ...]\n",
            "\n",
            "Cut up fasta file in non-overlapping or overlapping parts of equal length.\n",
            "\n",
            "Optionally creates a BED-file where the cutup contigs are specified in terms\n",
            "of the original contigs. This can be used as input to concoct_coverage_table.py.\n",
            "\n",
            "positional arguments:\n",
            "  contigs\n",
            "    Fasta files\n",
            "    with\n",
            "    contigs\n",
            "\n",
            "options:\n",
            "  -h, --help\n",
            "    show this\n",
            "    help\n",
            "    message and\n",
            "    exit\n",
            "  -c CHUNK_SIZE, --chunk_size CHUNK_SIZE\n",
            "    Chunk size\n",
            "  -o OVERLAP_SIZE, --overlap_size OVERLAP_SIZE\n",
            "    Overlap\n",
            "    size\n",
            "  -m, --merge_last\n",
            "    Concatenate\n",
            "    final part\n",
            "    to last\n",
            "    contig\n",
            "  -b BEDFILE, --bedfile BEDFILE\n",
            "    BEDfile to\n",
            "    be created\n",
            "    with exact\n",
            "    regions of\n",
            "    the\n",
            "    original\n",
            "    contigs cor\n",
            "    responding\n",
            "    to the\n",
            "    newly\n",
            "    created\n",
            "    contigs\n"
          ]
        }
      ],
      "source": [
        "!pip install checkm-genome\n",
        "!pip install opentsne==0.7.1\n",
        "!pip install hdbscan==0.8.29\n",
        "!pip install wget\n",
        "import wget\n",
        "wget.download('https://github.com/BinPro/CONCOCT/raw/develop/scripts/cut_up_fasta.py')\n",
        "# !python cut_up_fasta.py -h\n",
        "import os\n",
        "import shutil\n",
        "import itertools\n",
        "import argparse\n",
        "from datetime import datetime\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import seaborn as sns\n",
        "sns.set(style='white', color_codes=True)\n",
        "import numpy as np\n",
        "np.random.seed()\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.cm as cm\n",
        "import matplotlib.ticker\n",
        "import matplotlib.animation as animation\n",
        "from openTSNE import TSNE\n",
        "import hdbscan\n",
        "from skimage.measure import EllipseModel\n",
        "from matplotlib.patches import Ellipse\n",
        "from scipy import linalg\n",
        "import joblib\n",
        "from sklearn.metrics import silhouette_score\n",
        "from termcolor import colored\n",
        "from sklearn.covariance import EllipticEnvelope\n",
        "from sklearn.decomposition import FastICA\n",
        "from hyperopt import STATUS_OK, Trials, fmin, hp, tpe"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pd.set_option('display.max_rows', 50000)\n",
        "pd.set_option('display.max_columns', 50000)\n",
        "pd.set_option('max_colwidth', 1000)\n",
        "\n",
        "search_space = {\n",
        "    'min_cluster_size': hp.quniform('x_min_cluster_size', 10, 75, 1),\n",
        "    'min_samples': hp.quniform('x_min_samples', 5, 60, 1),\n",
        "    'cluster_selection_epsilon': hp.uniform('x_cluster_selection_epsilon', 0, 0.5)\n",
        "               }\n",
        "\n",
        "trials = Trials()"
      ],
      "metadata": {
        "id": "psy6U1sDFgel"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def hyperspace(search_space):\n",
        "\n",
        "    global jobs\n",
        "    global min_cluster_size_list\n",
        "    global min_samples_list\n",
        "    global epsilon_list\n",
        "    global noise_list\n",
        "    global silhouette_list\n",
        "    global fraction_list\n",
        "    global sscore_best\n",
        "    global failed_score_best\n",
        "    global noise_best\n",
        "    global cluster_list\n",
        "    global noise_threshold\n",
        "\n",
        "    print('\\n Current HDBSCAN parameters: min_cluster_size = %d  min_samples = %d  cluster_selection_epsilon = %.5f' % (search_space['min_cluster_size'], search_space['min_samples'], search_space['cluster_selection_epsilon']) )\n",
        "    min_cluster_size_list.append(int(search_space['min_cluster_size']))\n",
        "    min_samples_list.append(int(search_space['min_samples']))\n",
        "    epsilon_list.append(search_space['cluster_selection_epsilon'])\n",
        "    hdbscanner = hdbscan.HDBSCAN(min_cluster_size=int(search_space['min_cluster_size']), min_samples=int(search_space['min_samples']), cluster_selection_epsilon=search_space['cluster_selection_epsilon'], core_dist_n_jobs=jobs, prediction_data=True)\n",
        "\n",
        "    tmp = train\n",
        "    tmp['clabels'] = hdbscanner.fit_predict(train[col_names].values)\n",
        "    noise = tmp.loc[tmp.clabels == -1]\n",
        "    noise_list.append(len(noise))\n",
        "    cluster_list.append(len(np.unique(tmp.clabels))-1)\n",
        "    fraction_list.append(len(noise)/float(total_points))\n",
        "    if len(noise) < noise_best:\n",
        "        noise_best = len(noise)\n",
        "        noise_str = colored('%.3f %%' % (100*(len(noise)/float(total_points))), 'white', 'on_red')\n",
        "    else:\n",
        "        noise_str = str('%.3f %%' % (100*(len(noise)/float(total_points))))\n",
        "    clean = tmp.loc[tmp.clabels != -1]\n",
        "    clean.reset_index(drop=True, inplace=True)\n",
        "    clean_data = clean.drop(['clabels'], axis=1).values\n",
        "    sscore = silhouette_score(clean_data, clean['clabels'].values, metric='euclidean')\n",
        "    if (noise_threshold>(len(noise)/float(total_points))):\n",
        "        silhouette_list.append(sscore)\n",
        "    else:\n",
        "        silhouette_list.append(0.1)\n",
        "    if (sscore > sscore_best) and (noise_threshold>(len(noise)/float(total_points))):\n",
        "        sscore_best = sscore\n",
        "        sscore_str = colored('%.5f' % sscore, 'white', 'on_blue')\n",
        "    elif (sscore > sscore_best) and (sscore > failed_score_best) and (noise_threshold<(len(noise)/float(total_points))):\n",
        "        failed_score_best = sscore\n",
        "        sscore_str = colored('%.5f' % sscore, 'red', 'on_yellow')\n",
        "    else:\n",
        "        sscore_str = str('%.5f' % sscore)\n",
        "    if args.verbose:\n",
        "        print(' silhouette_score: %s  noise: %s  clusters: %d' % (sscore_str, noise_str, np.unique(clean['clabels'].values).shape[0]) )\n",
        "\n",
        "    std_score = 0.01\n",
        "    if (noise_threshold>(len(noise)/float(total_points))):\n",
        "        val_score = -1.0 * sscore\n",
        "    else:\n",
        "        val_score = -0.1\n",
        "\n",
        "    return {'loss': val_score, 'loss_variance': std_score, 'status': STATUS_OK }"
      ],
      "metadata": {
        "id": "14My1j4_Fj5v"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EllipsoidTool:\n",
        "    \"\"\"Some stuff for playing with ellipsoids\"\"\"\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def getMinVolEllipse(self, P=None, tolerance=0.001):\n",
        "        \"\"\" Find the minimum volume ellipsoid which holds all the points\n",
        "\n",
        "        Based on work by Nima Moshtagh\n",
        "        http://www.mathworks.com/matlabcentral/fileexchange/9542\n",
        "        and also by looking at:\n",
        "        http://cctbx.sourceforge.net/current/python/scitbx.math.minimum_covering_ellipsoid.html\n",
        "        Which is based on the first reference anyway!\n",
        "\n",
        "        Here, P is a numpy array of N dimensional points like this:\n",
        "        P = [[x,y,z,...], <-- one point per line\n",
        "             [x,y,z,...],\n",
        "             [x,y,z,...]]\n",
        "\n",
        "        Returns:\n",
        "        (center, radii, rotation)\n",
        "\n",
        "        \"\"\"\n",
        "        (N, d) = np.shape(P)\n",
        "        d = float(d)\n",
        "\n",
        "        # Q will be our working array\n",
        "        Q = np.vstack([np.copy(P.T), np.ones(N)])\n",
        "        QT = Q.T\n",
        "\n",
        "        # initializations\n",
        "        err = 1.0 + tolerance\n",
        "        u = (1.0 / N) * np.ones(N)\n",
        "\n",
        "        # Khachiyan Algorithm\n",
        "        while err > tolerance:\n",
        "            V = np.dot(Q, np.dot(np.diag(u), QT))\n",
        "            M = np.diag(np.dot(QT, np.dot(\n",
        "                linalg.inv(V), Q)))  # M the diagonal vector of an NxN matrix\n",
        "            j = np.argmax(M)\n",
        "            maximum = M[j]\n",
        "            step_size = (maximum - d - 1.0) / ((d + 1.0) * (maximum - 1.0))\n",
        "            new_u = (1.0 - step_size) * u\n",
        "            new_u[j] += step_size\n",
        "            err = np.linalg.norm(new_u - u)\n",
        "            u = new_u\n",
        "\n",
        "        # center of the ellipse\n",
        "        center = np.dot(P.T, u)\n",
        "\n",
        "        # the A matrix for the ellipse\n",
        "        A = linalg.inv(\n",
        "            np.dot(P.T, np.dot(np.diag(u), P)) -\n",
        "            np.array([[a * b for b in center] for a in center])) / d\n",
        "\n",
        "        # Get the values we'd like to return\n",
        "        U, s, rotation = linalg.svd(A)\n",
        "        radii = 1.0 / np.sqrt(s)\n",
        "\n",
        "        return (center, radii, rotation)\n",
        "\n",
        "    def getEllipsoidVolume(self, radii):\n",
        "        \"\"\"Calculate the volume of the blob\"\"\"\n",
        "        return 4. / 3. * np.pi * radii[0] * radii[1] * radii[2]\n",
        "\n",
        "    def plotEllipsoid(self,\n",
        "                      center,\n",
        "                      radii,\n",
        "                      rotation,\n",
        "                      ax=None,\n",
        "                      plotAxes=False,\n",
        "                      cageColor='b',\n",
        "                      cageAlpha=0.2):\n",
        "        \"\"\"Plot an ellipsoid\"\"\"\n",
        "        make_ax = ax == None\n",
        "        if make_ax:\n",
        "            fig = plt.figure()\n",
        "            ax = fig.add_subplot(111, projection='3d')\n",
        "            ax.set_aspect('equal')\n",
        "\n",
        "        u = np.linspace(0.0, 2.0 * np.pi, 100)\n",
        "        v = np.linspace(0.0, np.pi, 100)\n",
        "\n",
        "        # cartesian coordinates that correspond to the spherical angles:\n",
        "        x = radii[0] * np.outer(np.cos(u), np.sin(v))\n",
        "        y = radii[1] * np.outer(np.sin(u), np.sin(v))\n",
        "        z = radii[2] * np.outer(np.ones_like(u), np.cos(v))\n",
        "        # rotate accordingly\n",
        "        for i in range(len(x)):\n",
        "            for j in range(len(x)):\n",
        "                [x[i, j], y[i, j], z[i, j]\n",
        "                 ] = np.dot([x[i, j], y[i, j], z[i, j]], rotation) + center\n",
        "\n",
        "        if plotAxes:\n",
        "            # make some purdy axes\n",
        "            axes = np.array([[radii[0], 0.0, 0.0], [0.0, radii[1], 0.0],\n",
        "                             [0.0, 0.0, radii[2]]])\n",
        "            # rotate accordingly\n",
        "            for i in range(len(axes)):\n",
        "                axes[i] = np.dot(axes[i], rotation)\n",
        "\n",
        "            # plot axes\n",
        "            for p in axes:\n",
        "                X3 = np.linspace(-p[0], p[0], 100) + center[0]\n",
        "                Y3 = np.linspace(-p[1], p[1], 100) + center[1]\n",
        "                Z3 = np.linspace(-p[2], p[2], 100) + center[2]\n",
        "                ax.plot(X3, Y3, Z3, color=cageColor)\n",
        "\n",
        "        # plot ellipsoid\n",
        "        # ax.plot_wireframe(x, y, z,  rstride=4, cstride=4, color=cageColor, alpha=cageAlpha)\n",
        "        ax.plot_wireframe(x,\n",
        "                          y,\n",
        "                          z,\n",
        "                          rstride=2,\n",
        "                          cstride=2,\n",
        "                          color=cageColor,\n",
        "                          alpha=cageAlpha)\n",
        "\n",
        "        if make_ax:\n",
        "            plt.show()\n",
        "            plt.close(fig)\n",
        "            del fig"
      ],
      "metadata": {
        "id": "P5tbF8xaF9LJ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def timer(start_time=None):\n",
        "    if not start_time:\n",
        "        start_time = datetime.now()\n",
        "        return start_time\n",
        "    elif start_time:\n",
        "        thour, temp_sec = divmod((datetime.now() - start_time).total_seconds(),\n",
        "                                 3600)\n",
        "        tmin, tsec = divmod(temp_sec, 60)\n",
        "        print('\\n Time taken: %i hours %i minutes and %s seconds.' %\n",
        "              (thour, tmin, round(tsec, 2)))"
      ],
      "metadata": {
        "id": "jty6A9QtGGZS"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def draw_tsne(data=None,\n",
        "              n_neighbors=15,\n",
        "              min_dist=0.1,\n",
        "              n_components=2,\n",
        "              metric='euclidean',\n",
        "              title=''):\n",
        "    print('n_neighbors=%d   min_dist=%.2f' % (n_neighbors, min_dist))\n",
        "    fit = tsne.tSNE(n_neighbors=n_neighbors,\n",
        "                    min_dist=min_dist,\n",
        "                    n_components=n_components,\n",
        "                    metric=metric)\n",
        "    start_time = timer(None)\n",
        "    u = fit.fit_transform(data)\n",
        "    timer(start_time)\n",
        "\n",
        "    hdbscanner = hdbscan.HDBSCAN(min_cluster_size=20)\n",
        "    labels = hdbscanner.fit_predict(u)\n",
        "    print('Clusters %d' % np.max(labels))\n",
        "\n",
        "    fig = plt.figure(figsize=(7, 6))\n",
        "    if n_components == 1:\n",
        "        ax = fig.add_subplot(111)\n",
        "        cb = ax.scatter(u[:, 0], range(len(u)), cmap=cm, c=labels, s=2)\n",
        "        plt.colorbar(cb)\n",
        "    if n_components == 2:\n",
        "        ax = fig.add_subplot(111)\n",
        "        cb = ax.scatter(u[:, 0], u[:, 1], cmap=cm, c=labels, s=2)\n",
        "        plt.colorbar(cb)\n",
        "    if n_components == 3:\n",
        "        ax = fig.add_subplot(111, projection='3d')\n",
        "        cb = ax.scatter(u[:, 0], u[:, 1], u[:, 2], cmap=cm, c=labels, s=2)\n",
        "        plt.colorbar(cb)\n",
        "    plt.title(title, fontsize=16)\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def plot_results(X, Y_, nclus, index, title):\n",
        "\n",
        "    unique_labels = np.arange(nclus).astype(np.int)\n",
        "    splot = plt.subplot(1, 2, index)\n",
        "    splot.tick_params(axis='both', which='major', labelsize=12)\n",
        "    splot.tick_params(axis='both', which='minor', labelsize=12)\n",
        "    for i, (zz, color) in enumerate(zip(unique_labels, color_iter_one)):\n",
        "        if not np.any(Y_ == i):\n",
        "            continue\n",
        "        plt.scatter(X[Y_ == zz, 0],\n",
        "                    X[Y_ == zz, 1],\n",
        "                    marker='.',\n",
        "                    s=args.point_size,\n",
        "                    c=color)\n",
        "\n",
        "    if np.min(Y_) == -1:\n",
        "        plt.scatter(X[Y_ == -1, 0],\n",
        "                    X[Y_ == -1, 1],\n",
        "                    marker='.',\n",
        "                    s=args.point_size,\n",
        "                    c='k')\n",
        "\n",
        "    ell = EllipseModel()\n",
        "    for zz in unique_labels:\n",
        "        dp = X[Y_ == zz]\n",
        "        in_out = EllipticEnvelope(contamination=0.05).fit_predict(dp)\n",
        "        a_points = dp[in_out == 1]\n",
        "        ell_status = ell.estimate(a_points)\n",
        "        if ell_status:\n",
        "            xc, yc, a, b, theta = ell.params\n",
        "            ell_patch = Ellipse((xc, yc),\n",
        "                                3 * a,\n",
        "                                3 * b,\n",
        "                                theta * 180 / np.pi,\n",
        "                                edgecolor='red',\n",
        "                                facecolor='none')\n",
        "            splot.add_patch(ell_patch)\n",
        "            plt.text(xc, yc, str(zz), fontsize=11)\n",
        "\n",
        "    plt.gca().set_aspect('equal', adjustable='box')\n",
        "    plt.xlabel('Dimension 1')\n",
        "    plt.ylabel('Dimension 2')\n",
        "    plt.title(title, fontsize=15)\n",
        "\n",
        "def ani_update(embedding, ax, pathcol):\n",
        "    # Update point positions\n",
        "    pathcol.set_offsets(embedding)\n",
        "\n",
        "    # Adjust x/y limits so all the points are visible\n",
        "    ax.set_xlim(np.min(embedding[:, 0])-5, np.max(embedding[:, 0])+5)\n",
        "    ax.set_ylim(np.min(embedding[:, 1])-5, np.max(embedding[:, 1])+5)\n",
        "\n",
        "    return [pathcol]"
      ],
      "metadata": {
        "id": "ReirbEeFGKS8"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if os.access(args.input_file, os.R_OK):\n",
        "\n",
        "    if not os.path.exists(args.bins):\n",
        "        #        os.mkdir(args.bins)\n",
        "        os.makedirs(args.bins)  # to create a directory recursively\n",
        "    else:\n",
        "        print(\n",
        "            '\\n !! The directory you chose already exists, and its contents will be cleared !!'\n",
        "        )\n",
        "        for root, dirs, files in os.walk(args.bins):\n",
        "            for name in files:\n",
        "                os.remove(os.path.join(root, name))\n",
        "            for name in dirs:\n",
        "                shutil.rmtree(os.path.join(root, name))\n",
        "\n",
        "    if args.verbose:\n",
        "        print('\\n Splitting DNA sequences into %s pieces ...' % hc_abbrev)\n",
        "    os.system('cut_up_fasta.py -c %d -o %d -m %s > contigs_%s.fasta' %\n",
        "              (hc_size, lc_size, args.input_file, hc_abbrev))\n",
        "    if args.verbose:\n",
        "        print('\\n Removing contigs smaller than %s ...' % lc_abbrev)\n",
        "    os.system('seqtk seq -L %d contigs_%s.fasta > contigs_%s_%s.fasta' %\n",
        "              (lc_size, hc_abbrev, hc_abbrev, lc_abbrev))\n",
        "    if args.verbose:\n",
        "        print('\\n Calculating %d-mer frequencies ...' % args.kmer_size)\n",
        "    os.system(\n",
        "        #        'calc.kmerfreq.pl -i contigs_%s_%s.fasta -o contigs_%s_%s.%dmer.tab -k %d > /dev/null'\n",
        "        'checkm tetra -t 6 contigs_%s_%s.fasta contigs_%s_%s.%dmer.tab > /dev/null'\n",
        "        % (hc_abbrev, lc_abbrev, hc_abbrev, lc_abbrev, args.kmer_size))\n",
        "    os.system('cp contigs_%s_%s.%dmer.tab contigs_%s_%s.%dmer.csv' %\n",
        "              (hc_abbrev, lc_abbrev, args.kmer_size, hc_abbrev, lc_abbrev,\n",
        "               args.kmer_size))\n",
        "    os.system('perl -pi -e \"s/\\t/\\,/g\" contigs_%s_%s.%dmer.csv' %\n",
        "              (hc_abbrev, lc_abbrev, args.kmer_size))\n",
        "    os.system(\n",
        "        'awk -F , \"{print \\$1}\" contigs_%s_%s.%dmer.csv > contigs_%s_%s.%dmer_index.csv'\n",
        "        % (hc_abbrev, lc_abbrev, args.kmer_size, hc_abbrev, lc_abbrev,\n",
        "           args.kmer_size))\n",
        "    os.system(\n",
        "        'delete_cols.py contigs_%s_%s.%dmer.csv contigs_%s_%s.%dmer_noindex.csv 0'\n",
        "        % (hc_abbrev, lc_abbrev, args.kmer_size, hc_abbrev, lc_abbrev,\n",
        "           args.kmer_size))\n",
        "    #    train_test = pd.read_csv('contigs_%s_%s.%dmer_noindex.csv' % (hc_abbrev, lc_abbrev, args.kmer_size) )\n",
        "\n",
        "    train_data = pd.read_csv('contigs_%s_%s.%dmer_noindex.csv' %\n",
        "                             (hc_abbrev, lc_abbrev, args.kmer_size))\n",
        "    train_data = train_data.values\n",
        "    if (args.theta_val == -1.0):\n",
        "        if train_data.shape[0] <= 10000:\n",
        "            theta_val = 0.1\n",
        "            early_exag = 1000\n",
        "            iters = 3000\n",
        "            psize = 2\n",
        "        if (train_data.shape[0] > 10000) and (train_data.shape[0] <= 20000):\n",
        "            theta_val = 0.2\n",
        "            early_exag = 1500\n",
        "            iters = 4000\n",
        "            psize = 1\n",
        "        if train_data.shape[0] > 20000:\n",
        "            theta_val = 0.5\n",
        "            early_exag = 2000\n",
        "            iters = 5000\n",
        "            psize = 1\n",
        "    else:\n",
        "        if train_data.shape[0] <= 10000:\n",
        "            theta_val = args.theta_val\n",
        "            early_exag = 1000\n",
        "            iters = 3000\n",
        "            psize = 2\n",
        "        if (train_data.shape[0] > 10000) and (train_data.shape[0] <= 20000):\n",
        "            theta_val = args.theta_val\n",
        "            early_exag = 1500\n",
        "            iters = 4000\n",
        "            psize = 1\n",
        "        if train_data.shape[0] > 20000:\n",
        "            theta_val = args.theta_val\n",
        "            early_exag = 2000\n",
        "            iters = 5000\n",
        "            psize = 1\n",
        "\n",
        "    if args.dims == 2:\n",
        "        embeddings = []\n",
        "        if args.ica:\n",
        "            ICA = FastICA(n_components=8, whiten=False, max_iter=20000, tol=0.0001)\n",
        "            train_data_ICA = ICA.fit_transform(train_data)\n",
        "        tsne = TSNE(perplexity=args.perplexity,\n",
        "                    metric=args.tsne_metric,\n",
        "                    n_jobs=jobs,\n",
        "                    learning_rate='auto',\n",
        "                    negative_gradient_method='bh',\n",
        "                    theta=theta_val,\n",
        "#                    initialization='spectral',\n",
        "                    initialization=args.initial_embedding,\n",
        "                    early_exaggeration_iter=early_exag,\n",
        "                    early_exaggeration=18.0,\n",
        "                    n_iter=iters,\n",
        "                    # The embedding will be appended to the list we defined above, make sure we copy the\n",
        "                    # embedding, otherwise the same object reference will be stored for every iteration\n",
        "                    callbacks=lambda it, err, emb: embeddings.append(np.array(emb)),\n",
        "                    # This should be done on every iteration\n",
        "                    callbacks_every_iters=10,\n",
        "                    verbose=args.verbose)\n",
        "        start_time = timer(None)\n",
        "        if args.ica:\n",
        "            train = tsne.fit(train_data_ICA)\n",
        "        else:\n",
        "            train = tsne.fit(train_data)\n",
        "\n",
        "        embeddings = embeddings[(int(early_exag/10)-2):]\n",
        "        fig = plt.figure(figsize=(6, 6))\n",
        "        ax = fig.add_axes([0, 0, 1, 1])\n",
        "        ax.axis('off')\n",
        "        plt.tight_layout()\n",
        "        plt.gca().set_aspect('equal', adjustable='box')\n",
        "        ax.set_xticks([]), ax.set_yticks([])\n",
        "        pathcol = ax.scatter(embeddings[0][:, 0], embeddings[0][:, 1], c='r', s=psize, rasterized=True)\n",
        "        anim = animation.FuncAnimation(fig, ani_update, fargs=(ax, pathcol), interval=100, frames=embeddings, blit=True)\n",
        "        ani_name = args.tsne_plot.rsplit('.', 1)[0] + '.gif'\n",
        "        mp4_name = args.tsne_plot.rsplit('.', 1)[0] + '.mp4'\n",
        "        anim.save(ani_name, dpi=100, writer=animation.PillowWriter(fps=15))\n",
        "        anim.save(mp4_name, dpi=100, fps=15)\n",
        "        plt.close()\n",
        "\n",
        "        total_points = train.shape[0]\n",
        "        train = pd.DataFrame(train)\n",
        "        timer(start_time)\n",
        "    if args.dims == 3:\n",
        "        os.system(\n",
        "            'TSNEGenerator -i contigs_%s_%s.%dmer_noindex.csv -o data.dat -d 3 -p 20 -r %d -m 6000 > /dev/null'\n",
        "            % (hc_abbrev, lc_abbrev, args.kmer_size, rand_num))\n",
        "        print('\\n Starting tSNE calculation. This may take a while ...')\n",
        "        start_time = timer(None)\n",
        "        os.system('bh_tsne_exag')\n",
        "        timer(start_time)\n",
        "        os.system('TSNEReader -i result.dat -o tmp.csv > /dev/null')\n",
        "        train = pd.read_csv('tmp.csv', header=None)\n",
        "        total_points = train.shape[0]\n",
        "    if args.dims == 2:\n",
        "        train.columns = ['tSNE_X', 'tSNE_Y']\n",
        "    else:\n",
        "        train.columns = ['tSNE_X', 'tSNE_Y', 'tSNE_Z']\n",
        "    train.to_csv('contigs_hdbscan_%s_%s_%dD_%dmer_opentSNE.csv' %\n",
        "                 (hc_abbrev, lc_abbrev, args.dims, args.kmer_size),\n",
        "                 index=False)\n",
        "\n",
        "    col_names = train.columns.values\n",
        "    col_names_X = train.columns[0]\n",
        "    col_names_Y = train.columns[1]\n",
        "    if args.dims == 3:\n",
        "        col_names_Z = train.columns[2]\n",
        "\n",
        "    if args.dims == 2:\n",
        "        plt.figure(figsize=(10, 10))\n",
        "        plt.gca().set_aspect('equal', adjustable='box')\n",
        "        plt.scatter(train[col_names_X],\n",
        "                    train[col_names_Y],\n",
        "                    marker='.',\n",
        "                    s=args.point_size,\n",
        "                    color='r')\n",
        "        plt.xlabel('Dimension 1')\n",
        "        plt.ylabel('Dimension 2')\n",
        "        plt.title('Initial tSNE embedding before clustering')\n",
        "        plt.tight_layout()\n",
        "        plt.savefig('scatter_' + args.tsne_plot, dpi=300)\n",
        "        plt.show()\n",
        "        plt.close()\n",
        "\n",
        "    if args.dims == 3:\n",
        "        fig = plt.figure(figsize=(10, 10))\n",
        "        ax = fig.add_subplot(111, projection='3d')\n",
        "        ax.set_aspect('equal')\n",
        "        ax.set_xlabel('Dimension 1')\n",
        "        ax.set_ylabel('Dimension 2')\n",
        "        ax.set_zlabel('Dimension 3')\n",
        "        ax.scatter(train[col_names_X],\n",
        "                   train[col_names_Y],\n",
        "                   train[col_names_Z],\n",
        "                   marker='.',\n",
        "                   s=args.point_size,\n",
        "                   c='r')\n",
        "\n",
        "        plt.title('Initial tSNE embedding before clustering')\n",
        "        # plt.legend(loc='best')\n",
        "        plt.tight_layout()\n",
        "        plt.savefig('scatter_' + args.tsne_plot, dpi=300)\n",
        "        plt.show()\n",
        "        plt.close()\n",
        "\n",
        "    # Fit a Dirichlet process Gaussian mixture using given number of components\n",
        "    print(\n",
        "        '\\n Starting HDBSCAN clustering. This may take a while ...\\n')\n",
        "    start_time = timer(None)\n",
        "\n",
        "    min_cluster_size_list = []\n",
        "    min_samples_list = []\n",
        "    epsilon_list = []\n",
        "    noise_list = []\n",
        "    silhouette_list = []\n",
        "    fraction_list = []\n",
        "    sscore_best = -1\n",
        "    failed_score_best = -1\n",
        "    noise_best = total_points\n",
        "    cluster_list = []\n",
        "    noise_threshold = args.noise_threshold\n",
        "    if not args.hyperopt:\n",
        "        for kk in np.arange(10,41,2):\n",
        "            for jj in np.arange(10,21):\n",
        "                print(' min_cluster_size: %d   min_samples: %d' % (kk, jj) )\n",
        "                min_cluster_size_list.append(int(kk))\n",
        "                min_samples_list.append(int(jj))\n",
        "                epsilon_list.append(0.)\n",
        "                hdbscanner = hdbscan.HDBSCAN(min_cluster_size=int(kk), min_samples=int(jj), core_dist_n_jobs=jobs, prediction_data=True)\n",
        "                # hdbscanner = hdbscan.HDBSCAN(min_cluster_size=kk, core_dist_n_jobs=jobs, prediction_data=True)\n",
        "                tmp = train\n",
        "                tmp['clabels'] = hdbscanner.fit_predict(train[col_names].values)\n",
        "                noise = tmp.loc[tmp.clabels == -1]\n",
        "                noise_list.append(len(noise))\n",
        "                cluster_list.append(len(np.unique(tmp.clabels))-1)\n",
        "                fraction_list.append(len(noise)/float(total_points))\n",
        "                if len(noise) < noise_best:\n",
        "                    noise_best = len(noise)\n",
        "                    noise_str = colored('%.3f %%' % (100*(len(noise)/float(total_points))), 'white', 'on_red')\n",
        "                else:\n",
        "                    noise_str = str('%.3f %%' % (100*(len(noise)/float(total_points))))\n",
        "                clean = tmp.loc[tmp.clabels != -1]\n",
        "                clean.reset_index(drop=True, inplace=True)\n",
        "                clean_data = clean.drop(['clabels'], axis=1).values\n",
        "                sscore = silhouette_score(clean_data, clean['clabels'].values, metric='euclidean')\n",
        "                silhouette_list.append(sscore)\n",
        "                if sscore > sscore_best:\n",
        "                    sscore_best = sscore\n",
        "                    sscore_str = colored('%.5f' % sscore, 'white', 'on_blue')\n",
        "                else:\n",
        "                    sscore_str = str('%.5f' % sscore)\n",
        "                if args.verbose:\n",
        "                    print(' silhouette_score: %s  noise: %s  clusters: %d' % (sscore_str, noise_str, np.unique(clean['clabels'].values).shape[0]) )\n",
        "\n",
        "    if args.hyperopt:\n",
        "        best = fmin(\n",
        "                    fn=hyperspace,  # \"Loss\" function to minimize\n",
        "                    space=search_space,  # Hyperparameter space\n",
        "#                    algo=anneal.suggest,  # Simulated annealing\n",
        "                    algo=tpe.suggest,  # Tree-structured Parzen Estimator (TPE)\n",
        "                    trials=trials,\n",
        "                    max_evals=200,  # Perform 200 trials\n",
        "#                    max_evals=10,  # Perform 10 trials\n",
        "                   )\n",
        "        print('-'*70)\n",
        "        print('Best HDBSCAN parameters:')\n",
        "        print(str(best))\n",
        "\n",
        "    timer(start_time)\n",
        "\n",
        "    df = pd.DataFrame(min_cluster_size_list, columns=['min_cluster_size'])\n",
        "    df['min_samples'] = min_samples_list\n",
        "    df['epsilon'] = epsilon_list\n",
        "    df['clusters'] = cluster_list\n",
        "#    df['noise'] = noise_list\n",
        "    df['noise'] = fraction_list\n",
        "    df['noise'] = 100*df['noise'].values\n",
        "    df['silhouette_score'] = silhouette_list\n",
        "    df.sort_values('silhouette_score', ascending=False, inplace=True)\n",
        "    df.reset_index(drop=True, inplace=True)\n",
        "    arr = df.values\n",
        "    print(df)\n",
        "\n",
        "    nclus = arr[0][3]\n",
        "    if not args.hyperopt:\n",
        "        hdbscanner = hdbscan.HDBSCAN(min_cluster_size=int(arr[0][0]), min_samples=int(arr[0][1]), core_dist_n_jobs=jobs, prediction_data=True)\n",
        "    if args.hyperopt:\n",
        "        hdbscanner = hdbscan.HDBSCAN(min_cluster_size=int(arr[0][0]), min_samples=int(arr[0][1]), cluster_selection_epsilon=float(arr[0][2]), core_dist_n_jobs=jobs, prediction_data=True)\n",
        "    clabels = hdbscanner.fit_predict(train[col_names].values)\n",
        "    joblib.dump(hdbscanner, hdb_model)\n",
        "\n",
        "    clusters = pd.DataFrame(clabels.astype(np.int))\n",
        "    train['cluster_labels'] = clabels\n",
        "    train_new = train.loc[train.cluster_labels != -1]\n",
        "    train_new.reset_index(drop=True, inplace=True)\n",
        "\n",
        "    if args.dims == 2:\n",
        "        plt.figure(figsize=(22, 10))\n",
        "        if args.black_bkg:\n",
        "            plt.style.use('dark_background')\n",
        "        color_iter = itertools.cycle([\n",
        "            'orchid', 'cyan', 'violet', 'lawngreen', 'cornflowerblue', 'tomato',\n",
        "            'gold', 'deeppink', 'lime', 'darkorange', 'olive', 'lightcoral',\n",
        "            'tan', 'sandybrown', 'palegreen', 'lightslategrey',\n",
        "            'teal', 'red', 'dodgerblue', 'darkslategrey', 'mediumslateblue',\n",
        "            'orangered', 'springgreen', 'mediumaquamarine', 'darkgrey', 'firebrick',\n",
        "            'salmon', 'darkkhaki', 'yellowgreen', 'forestgreen', 'cadetblue',\n",
        "            'plum', 'seagreen', 'royalblue', 'goldenrod', 'slateblue', 'fuchsia',\n",
        "            'khaki', 'chocolate', 'hotpink', 'moccasin', 'crimson', 'peachpuff'\n",
        "        ])\n",
        "        color_iter_one = itertools.islice(color_iter, 1, None)\n",
        "        plot_results(train[col_names].values, clabels, nclus, 1, args.plot_title)\n",
        "        color_iter = itertools.cycle([\n",
        "            'orchid', 'cyan', 'violet', 'lawngreen', 'cornflowerblue', 'tomato',\n",
        "            'gold', 'deeppink', 'lime', 'darkorange', 'olive', 'lightcoral',\n",
        "            'tan', 'sandybrown', 'palegreen', 'lightslategrey',\n",
        "            'teal', 'red', 'dodgerblue', 'darkslategrey', 'mediumslateblue',\n",
        "            'orangered', 'springgreen', 'mediumaquamarine', 'darkgrey', 'firebrick',\n",
        "            'salmon', 'darkkhaki', 'yellowgreen', 'forestgreen', 'cadetblue',\n",
        "            'plum', 'seagreen', 'royalblue', 'goldenrod', 'slateblue', 'fuchsia',\n",
        "            'khaki', 'chocolate', 'hotpink', 'moccasin', 'crimson', 'peachpuff'\n",
        "        ])\n",
        "        color_iter_one = itertools.islice(color_iter, 1, None)\n",
        "        plot_results(train_new[col_names].values, train_new['cluster_labels'].values, nclus, 2, args.plot_title + ' no unclustered')\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(args.tsne_plot, dpi=300)\n",
        "        plt.show()\n",
        "        plt.close()\n",
        "\n",
        "    if args.dims == 3:\n",
        "        ET = EllipsoidTool()\n",
        "        fig = plt.figure(figsize=(10, 8))\n",
        "        if args.black_bkg:\n",
        "            plt.style.use('dark_background')\n",
        "        color_iter = itertools.cycle([\n",
        "            'orchid', 'cyan', 'violet', 'lawngreen', 'cornflowerblue', 'tomato',\n",
        "            'gold', 'deeppink', 'lime', 'darkorange', 'olive', 'lightcoral',\n",
        "            'tan', 'sandybrown', 'palegreen', 'lightslategrey',\n",
        "            'teal', 'red', 'dodgerblue', 'darkslategrey', 'mediumslateblue',\n",
        "            'orangered', 'springgreen', 'mediumaquamarine', 'darkgrey', 'firebrick',\n",
        "            'salmon', 'darkkhaki', 'yellowgreen', 'forestgreen', 'cadetblue',\n",
        "            'plum', 'seagreen', 'royalblue', 'goldenrod', 'slateblue', 'fuchsia',\n",
        "            'khaki', 'chocolate', 'hotpink', 'moccasin', 'crimson', 'peachpuff'\n",
        "        ])\n",
        "        color_iter_one = itertools.islice(color_iter, 1, None)\n",
        "\n",
        "        ax = fig.add_subplot(111, projection='3d')\n",
        "        ax.set_aspect('equal')\n",
        "        ax.set_xlabel('Dimension 1')\n",
        "        ax.set_ylabel('Dimension 2')\n",
        "        ax.set_zlabel('Dimension 3')\n",
        "\n",
        "        unique_clusters = np.arange(nclus).astype(np.int)\n",
        "        for i, (zz, color) in enumerate(zip(unique_clusters, color_iter_one)):\n",
        "            ax.scatter(train.loc[train.cluster_labels == zz, col_names_X],\n",
        "                       train.loc[train.cluster_labels == zz, col_names_Y],\n",
        "                       train.loc[train.cluster_labels == zz, col_names_Z],\n",
        "                       marker='.',\n",
        "                       s=args.point_size,\n",
        "                       c=color)\n",
        "\n",
        "            dp = train.loc[train.cluster_labels == zz]\n",
        "            a_points = dp[col_names].values\n",
        "            # find the ellipsoid\n",
        "            (center, radii, rotation) = ET.getMinVolEllipse(a_points, .001)\n",
        "            # plot the ellipsoid\n",
        "            ET.plotEllipsoid(center,\n",
        "                             radii,\n",
        "                             rotation,\n",
        "                             ax=ax,\n",
        "                             plotAxes=False,\n",
        "                             cageColor=color,\n",
        "                             cageAlpha=0.1)\n",
        "            xc, yc, zc = center\n",
        "            ax.text(xc, yc, zc, str(zz), 'y', fontsize=12)\n",
        "\n",
        "        plt.title(args.plot_title, fontsize='16')\n",
        "        plt.tight_layout()\n",
        "\n",
        "        plt.savefig(args.tsne_plot, dpi=300)\n",
        "        plt.show()\n",
        "        plt.close()\n",
        "\n",
        "    if args.verbose:\n",
        "        print('\\n tSNE plot saved as %s' % args.tsne_plot)\n",
        "\n",
        "    train_index = pd.read_csv('contigs_%s_%s.%dmer_index.csv' %\n",
        "                              (hc_abbrev, lc_abbrev, args.kmer_size))\n",
        "    train_index['cluster_labels'] = clabels.astype(np.int)\n",
        "    train_index.columns = ['contig_id', 'cluster_id']\n",
        "    train_index.to_csv('%dD_' % args.dims + args.tsne_clusters, index=False)\n",
        "    if args.verbose:\n",
        "        print('\\n Extracting clusters from %s\\n' %\n",
        "              ('%dD_' % args.dims + args.tsne_clusters))\n",
        "    os.system('merge_cutup_clustering.py %s > merged_%s' %\n",
        "              (('%dD_' % args.dims + args.tsne_clusters),\n",
        "               ('%dD_' % args.dims + args.tsne_clusters)))\n",
        "    os.system('extract_fasta_bins.py %s merged_%s --output_path %s' %\n",
        "              (args.input_file,\n",
        "               ('%dD_' % args.dims + args.tsne_clusters), args.bins))\n",
        "    if os.path.exists('%s/group_-1.fa' % args.bins):\n",
        "        os.system('mv -- %s/group_-1.fa %s/unclustered.fasta' % (args.bins, args.bins))\n",
        "\n",
        "# remove tmp files\n",
        "    if os.access('data.dat', os.R_OK):\n",
        "        os.system('rm data.dat')\n",
        "    if os.access('result.dat', os.R_OK):\n",
        "        os.system('rm result.dat')\n",
        "    if os.access('tmp.csv', os.R_OK):\n",
        "        os.system('rm tmp.csv')\n",
        "    if os.access('contigs_%s.fasta' % hc_abbrev, os.R_OK):\n",
        "        os.system('rm contigs_%s.fasta' % hc_abbrev)\n",
        "    if os.access('contigs_%s_%s.fasta' % (hc_abbrev, lc_abbrev), os.R_OK):\n",
        "        os.system('rm contigs_%s_%s.fasta' % (hc_abbrev, lc_abbrev))\n",
        "    if os.access(\n",
        "            'contigs_%s_%s.%dmer.tab' % (hc_abbrev, lc_abbrev, args.kmer_size),\n",
        "            os.R_OK):\n",
        "        os.system('rm contigs_%s_%s.%dmer.tab' %\n",
        "                  (hc_abbrev, lc_abbrev, args.kmer_size))\n",
        "    if os.access(\n",
        "            'contigs_%s_%s.%dmer.csv' % (hc_abbrev, lc_abbrev, args.kmer_size),\n",
        "            os.R_OK):\n",
        "        os.system('rm contigs_%s_%s.%dmer.csv' %\n",
        "                  (hc_abbrev, lc_abbrev, args.kmer_size))\n",
        "    if os.access(\n",
        "            'contigs_%s_%s.%dmer_index.csv' %\n",
        "        (hc_abbrev, lc_abbrev, args.kmer_size), os.R_OK):\n",
        "        os.system('rm contigs_%s_%s.%dmer_index.csv' %\n",
        "                  (hc_abbrev, lc_abbrev, args.kmer_size))\n",
        "    if os.access(\n",
        "            'contigs_%s_%s.%dmer_noindex.csv' %\n",
        "        (hc_abbrev, lc_abbrev, args.kmer_size), os.R_OK):\n",
        "        os.system('rm contigs_%s_%s.%dmer_noindex.csv' %\n",
        "                  (hc_abbrev, lc_abbrev, args.kmer_size))\n",
        "\n",
        "else:\n",
        "    parser.error(\n",
        "        '\\n !!! Input file \"%s\" does not exist in this directory !!!\\n' %\n",
        "        args.input_file)\n"
      ],
      "metadata": {
        "id": "C43q6au2Gbqp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cRdwP7Y2F1rD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}